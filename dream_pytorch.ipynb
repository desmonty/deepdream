{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDream - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by rewriting the deepdream code using PyTorch.\n",
    "Once this will be done, we'll be able to play around with the training data in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.JpegImagePlugin import JpegImageFile\n",
    "from scipy.ndimage.filters import gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"GPU found\")\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepDream Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PIL_to_Tensor(image: Image):\n",
    "    \"\"\"\n",
    "    Transform a PIL image into a Torch tensor.\n",
    "\n",
    "    :param image: PIL image.\n",
    "    :return: Tensor version of the PIL image.\n",
    "    \"\"\"\n",
    "    loader = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return loader(image)\n",
    "\n",
    "def to_PIL(image: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Convert Tensor to PIL Image\n",
    "\n",
    "    :param image: Tensor version of the PIL image.\n",
    "    :return: PIL image.\n",
    "    \"\"\"\n",
    "    return transforms.functional.to_pil_image(image.cpu())\n",
    "\n",
    "def load_image(path: str):\n",
    "    \"\"\"\n",
    "    Return a loaded image from a given path.\n",
    "\n",
    "    :param path: (str) relative path of the iamge.\n",
    "    :return: PIL image.\n",
    "    \"\"\"\n",
    "    image = Image.open(path)\n",
    "    return image\n",
    "\n",
    "def save_image(image, filename: str):\n",
    "    \"\"\"\n",
    "    Save image 'image' at path 'filename'\n",
    "\n",
    "    :param image: Image to save.\n",
    "    :param filename: (str) Path where to save the image.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Convert Tensor into PIL Image if necessary\n",
    "    if type(image) != Image.Image:\n",
    "        tmp_image = to_PIL(image)\n",
    "    else:\n",
    "        tmp_image = image\n",
    "    with open(filename, 'wb') as file:\n",
    "        tmp_image.save(filename, 'jpeg')\n",
    "    \n",
    "def plot_image(image: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Plot an image\n",
    "\n",
    "    :param image: Image to plot.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Convert Tensor to PIL Image if necessary\n",
    "    if type(image) == torch.Tensor:\n",
    "        image = to_PIL(image)\n",
    "    display(image)\n",
    "\n",
    "def resize(inputs, size: tuple=None, factor: float=None, interpolation='bilinear', device='cuda:0'):\n",
    "    \"\"\"\n",
    "    Resize  an image given a target size\n",
    "\n",
    "    :param inputs: (Tensor, PIL.Image) Image\n",
    "    :param size: (tuple<int, int>) Size of the new image.\n",
    "    :param factor: (float) Scale factor by which multiply the dimension of the image.\n",
    "    :param interpolation: (str) interpolation used\n",
    "    :param device: (str) Device where to compute the model.\n",
    "    :return: (Tensor, PIL.Image) resized image\n",
    "    \"\"\"\n",
    "    # Get GPU if there is one\n",
    "    if not torch.cuda.is_available() or 'cuda:' not in device:\n",
    "        device = \"cpu\"\n",
    "\n",
    "    is_image = False\n",
    "    if type(inputs) != torch.Tensor:\n",
    "        is_image = True\n",
    "        inputs = PIL_to_Tensor(inputs).to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = torch.nn.Upsample(\n",
    "            size=size,\n",
    "            scale_factor=factor,\n",
    "            mode=interpolation,\n",
    "            align_corners=True\n",
    "        ).to(device)\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    if is_image:\n",
    "        outputs = to_PIL(outputs.squeeze())\n",
    "\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# DeepDream Algorithm #\n",
    "#######################\n",
    "\n",
    "class DeepDream(object):\n",
    "    \"\"\"docstring for DeepDream\"\"\"\n",
    "    def __init__(self, image, network, device):\n",
    "        super(DeepDream, self).__init__()\n",
    "        self.image = image\n",
    "        self.network = network\n",
    "        self.device = device\n",
    "        self.mean = torch.Tensor([0.485, 0.456, 0.406]).to(self.device)\n",
    "        self.std = torch.Tensor([0.229, 0.224, 0.225]).to(self.device)\n",
    "\n",
    "    def apply(self, at_layer, iterations: int, lr: float, octave_scale: float, num_octaves: int=None, blend: float=0.5, one_in: int=1):\n",
    "        \"\"\"\n",
    "        Dream the image.\n",
    "\n",
    "        Note: If only one of 'octave_scale' and 'num_octaves' are provided\n",
    "              the other one will be automatically computed.\n",
    "              IT IS NOT GUARANTEED TO WORK. \n",
    "\n",
    "        :param at_layer: (int, str) Layer to look at during dreaming.\n",
    "        :param iterations: (int) Number of iterations of the Dream algorithms.\n",
    "        :param lr: (float) Learning_rate of the Dream algorithm\n",
    "        :param octave_scale: (float) Scale factor for the reduction of the image between two ocaves.\n",
    "        :param num_octaves: (int) Number of octaves (Times we'll apply the scale factor)\n",
    "        :param blend: (float) Blend factor between dreamed_image and normal image at each scale.\n",
    "        :return: Dreamt image, transformed so that its nice.\n",
    "        \"\"\"\n",
    "        #\n",
    "        model = self.construct_model(self.network, at_layer)\n",
    "        input_image = PIL_to_Tensor(self.image).to(self.device)\n",
    "        \n",
    "        # Complete parameters if not given.\n",
    "        if num_octaves is None:\n",
    "            min_dimension = min(input_image.size()[1:])\n",
    "            num_octaves = math.floor(math.log(min_dimension / 32) / math.log(octave_scale))\n",
    "        \n",
    "        if octave_scale is None:\n",
    "            max_dimension = max(input_image.size()[1:])\n",
    "            octave_scale = math.pow(max_dimension / 224, 1.0 / num_octaves)\n",
    "\n",
    "        # Transform the image in Tensor and preprocess it.\n",
    "        input_image = to_PIL(input_image)\n",
    "        preprocess = transforms.Compose([transforms.ToTensor(), transforms.Normalize(self.mean, self.std)])\n",
    "        input_image = preprocess(input_image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Generate zoomed verion of the original image, and reapply to get more.\n",
    "        octaves = [input_image]\n",
    "        for _ in range(num_octaves // one_in - 1):\n",
    "            new_octave = resize(octaves[-1], factor=1/octave_scale**one_in)\n",
    "            octaves.append(new_octave)\n",
    "\n",
    "        detail = torch.zeros_like(octaves[-1]).to(self.device)\n",
    "        \n",
    "        print(\"Octave: \", end=\"\")\n",
    "        for octave, octave_base in enumerate(octaves[::-1]):\n",
    "            if octave > 0:\n",
    "                # Upsample detail to new octave dimension\n",
    "                detail = resize(detail, size=list(octave_base.size()[2:4]))\n",
    "\n",
    "            # Add deep dream detail to new octave dimension\n",
    "            input_image = 2.0 * (blend * octave_base + (1.0 - blend) * detail)\n",
    "\n",
    "            # Get new deep dream image\n",
    "            dreamed_image = self.dream(input_image, model, iterations, lr)\n",
    "            \n",
    "            # Extract deep dream details\n",
    "            detail = dreamed_image - octave_base\n",
    "\n",
    "            print(octave+1, end=\" \")\n",
    "\n",
    "        dreamed_image = to_PIL(self.deprocess(dreamed_image))\n",
    "        print(\"Done !\")\n",
    "        return dreamed_image\n",
    "\n",
    "    def dream(self, input: torch.Tensor, model, iterations: int, lr: float):\n",
    "        \"\"\"\n",
    "        Main Dream function.\n",
    "        Updates the image to maximize outputs for n iterations\n",
    "\n",
    "        :param input: (Tensor) Image to dream on.\n",
    "        :param model: Complete model to use for the dreaming.\n",
    "        :param iterations: (int) Number of times we want to step toward the dream.\n",
    "        :param lr: (float) Learning rate.\n",
    "        :return: Dreamed image.\n",
    "        \"\"\"\n",
    "        # Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "        input = Variable(input.to(self.device), requires_grad=True)\n",
    "        for i in range(iterations):\n",
    "            model.zero_grad()\n",
    "            out = model(input)\n",
    "            loss = out.norm()\n",
    "            loss.backward()\n",
    "            \n",
    "            grad = input.grad.data.cpu().numpy()\n",
    "            sigma = (i * 4.0) / iterations + 0.5\n",
    "            grad_smooth1 = torch.Tensor(gaussian_filter(grad, sigma=sigma)).to(device)\n",
    "            grad_smooth2 = torch.Tensor(gaussian_filter(grad, sigma=sigma*2)).to(device)\n",
    "            grad_smooth3 = torch.Tensor(gaussian_filter(grad, sigma=sigma*0.5)).to(device)\n",
    "            grad = grad_smooth1 + grad_smooth2 + grad_smooth3\n",
    "            \n",
    "            std_grad = grad.std()\n",
    "            norm_lr = lr / std_grad\n",
    "            input.data += norm_lr * grad.data\n",
    "            input.data = self.clip(input.data)\n",
    "            input.grad.data.zero_()\n",
    "        return input\n",
    "\n",
    "    # Helpers\n",
    "    def clip(self, image_input: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Clip image according to mean and std in the network.\n",
    "\n",
    "        :param image_input: (Tensor) Image.\n",
    "        :return: Clipped image.\n",
    "        \"\"\"\n",
    "        for c in range(3):\n",
    "            m, s = self.mean[c], self.std[c]\n",
    "            image_input[0, c] = torch.clamp(image_input[0, c], -m / s, (1 - m) / s)\n",
    "        return image_input\n",
    "\n",
    "    def deprocess(self, image_input: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Deprocess the image_input. Basically just unnormalize it.\n",
    "\n",
    "        :param image_input: (Tensor) Image to unnormalize.\n",
    "        :return: Deprocessed image.\n",
    "        \"\"\"\n",
    "        image_input = image_input.squeeze() * self.std.reshape((3, 1, 1)) + self.mean.reshape((3, 1, 1))\n",
    "        image_input = torch.clamp(image_input, min=0.0, max=1.0)\n",
    "        return image_input\n",
    "\n",
    "    def construct_model(self, network, at_layer):\n",
    "        \"\"\"\n",
    "        Return a Sequential model ending by the 'at_layer'nth layer.\n",
    "\n",
    "        :param network: (torchvision.models) Network used for the image recognition.\n",
    "        :param at_layer: Layer where to stop the computation.\n",
    "        :return: Model that return the output at layer 'at_layer' when computing on model 'network'\n",
    "        \"\"\"\n",
    "        layers = list(network.features.children())\n",
    "        model = nn.Sequential(*layers[: (at_layer + 1)])\n",
    "        return model.to(self.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('images/dark_forest_2.jpg')\n",
    "print(\"Image Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce size of image\n",
    "image = resize(image, factor=3/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get network\n",
    "network = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers = range(23, 31)\n",
    "dreamMachine = DeepDream(image, network, device)\n",
    "\n",
    "for i in layers:\n",
    "    print(\"Layer:\", i)\n",
    "    dreamed_image = dreamMachine.apply(\n",
    "        at_layer=i,\n",
    "        iterations=20,\n",
    "        lr=0.015,\n",
    "        octave_scale=1.428,\n",
    "        num_octaves=4,\n",
    "        blend=0.5,\n",
    "    )\n",
    "    plot_image(resize(dreamed_image, factor=4/3))\n",
    "    #save_image(dreamed_image, f\"images_dreamed/mush_{str(i)}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "blend = range(0, 11)\n",
    "dreamMachine = DeepDream(image, network, device)\n",
    "\n",
    "for i in blend:\n",
    "    print(\"Layer:\", i)\n",
    "    dreamed_image = dreamMachine.apply(\n",
    "        at_layer=12,\n",
    "        iterations=10,\n",
    "        lr=0.01,\n",
    "        octave_scale=1.428,\n",
    "        num_octaves=4,\n",
    "        blend=i/10,\n",
    "    )\n",
    "    plot_image(dreamed_image)\n",
    "    #save_image(dreamed_image, f\"images_dreamed/mush_{str(i)}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
